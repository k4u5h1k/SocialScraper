{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEEDED LIBRARIES\n",
    "from os import path\n",
    "from requests import get,session\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from selenium import webdriver\n",
    "import json \n",
    "import re\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST WEBSITE NAMES\n",
    "twitter_url = \"https://twitter.com\"\n",
    "insta_url = \"https://www.instagram.com\"\n",
    "fb_url = \"https://m.facebook.com/public\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instagram Username:_cosec_\n",
      "\n",
      "Data dumped!\n"
     ]
    }
   ],
   "source": [
    "#INSTA INFO\n",
    "try:\n",
    "    insta_username = input(\"Instagram Username:\")\n",
    "    insta_final = f\"{insta_url}/{insta_username}/\"\n",
    "    user_page = get(insta_final)\n",
    "    insta_soup = bs(user_page.text,'lxml')\n",
    "    scripts = insta_soup.find('script', type=\"text/javascript\", text=re.compile('window._sharedData'))\n",
    "    stringified_json = scripts.text.replace('window._sharedData = ', '')[:-1]\n",
    "    final_data = json.loads(stringified_json)['entry_data']['ProfilePage'][0]\n",
    "    insta_username = final_data['graphql']['user']['username']\n",
    "    data_file = f\"{insta_username}'s_insta_data.json\" if not path.isfile(f\"{insta_username}'s_insta_data.json\") else f\"{insta_username}'s_insta_data_1.json\"\n",
    "    json.dump(final_data, open(data_file,\"w+\"), indent=4)\n",
    "    print(\"\\nData dumped!\")\n",
    "except:\n",
    "    print(f\"Sorry {insta_username} is not a valid instagram username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(username,site_name,dp_url):\n",
    "    count=0\n",
    "    filename = f\"{username}'s_{site_name}_dp.jpg\"\n",
    "    while True:\n",
    "        if not path.isfile(filename):\n",
    "            with open(filename, 'wb+') as handle:\n",
    "                response = get(dp_url, stream=True)\n",
    "                if not response.ok:\n",
    "                    print(response)\n",
    "                for block in response.iter_content(1024):\n",
    "                    if not block:\n",
    "                        break\n",
    "                    handle.write(block)\n",
    "        else:\n",
    "            count+=1\n",
    "            filename = f\"{username}'s_{site_name}_dp_{count}.jpg\"\n",
    "            continue\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP downloaded!\n"
     ]
    }
   ],
   "source": [
    "#DOWNLOAD INSTA DP\n",
    "dp_url = final_data['graphql']['user']['profile_pic_url_hd']\n",
    "filename = f\"{insta_username}'s_insta_dp.jpg\"\n",
    "count=0\n",
    "download(insta_username,\"insta\",dp_url)\n",
    "print(\"DP downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#FACEBOOK DP\n",
    "full_name = final_data['graphql']['user']['full_name']\n",
    "fb_search_url = f\"{fb_url}/{full_name}\"\n",
    "fb_search_results = get(fb_search_url)\n",
    "fb_soup = bs(fb_search_results.text,'lxml')\n",
    "fb_dp = fb_soup.find('img',{\"alt\":f\"{full_name}\"})\n",
    "print(list(i[\"src\"]for i in fb_dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a twitter username: realDonaldTrump\n",
      "{'name': 'Donald J. Trump', 'username': 'realDonaldTrump', 'birthday': None, 'biography': '45th President of the United States of America', 'website': 'Instagram.com/realDonaldTrump', 'profile_photo': 'https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_400x400.jpg'}\n"
     ]
    }
   ],
   "source": [
    "#TWITTER INFO\n",
    "username=input(\"Please enter a twitter username: \")\n",
    "page = get(f\"https://twitter.com/{username}\")\n",
    "try:\n",
    "    html = bs(page.text,'html.parser')\n",
    "except KeyError:\n",
    "    raise ValueError(\n",
    "        f'Oops! Either \"{username}\" does not exist or is private.')\n",
    "except ParserError:\n",
    "    pass\n",
    "# TODO: Check what kind of exception raising if no location\n",
    "location = html.find(\"span\",{\"class\":\"ProfileHeaderCard-locationText u-dir\"}).text\n",
    "birthday = html.find(\"span\",{\"class\":\"ProfileHeaderCard-birthdateText u-dir\"}).text.strip()\n",
    "if birthday:\n",
    "    birthday = birthday.replace('Born ', '')\n",
    "else:\n",
    "    birthday = None\n",
    "profile_photo = html.find(\"img\",{\"class\":\"ProfileAvatar-image\"}).attrs['src']\n",
    "page_title = html.find('title').text\n",
    "name = page_title[:page_title.find('(')].strip()\n",
    "biography = html.find(\"p\",{\"class\":\"ProfileHeaderCard-bio u-dir\"}).text\n",
    "website = html.find(\"a\",{\"class\":\"u-textUserColor\",\"rel\":\"me nofollow noopener\"}).text.strip()\n",
    "print(dict(\n",
    "    name = name,\n",
    "    username = username,\n",
    "    birthday = birthday,\n",
    "    biography = biography,\n",
    "    website = website,\n",
    "    profile_photo = profile_photo,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
