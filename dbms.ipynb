{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STUFF TO KEEP AT THE BACK OF MIND\n",
      "Below are methods to find a web element based on the locators in Selenium python bindings:\n",
      "find_element_by_id.\n",
      "find_element_by_name.\n",
      "find_element_by_xpath.\n",
      "find_element_by_link_text.\n",
      "find_element_by_partial_link_text.\n",
      "find_element_by_tag_name.\n",
      "find_element_by_class_name.\n",
      "find_element_by_css_selector.\n",
      "LINKEDIN - https://www.linkedin.com/sales/gmail/profile/viewByEmail/\n",
      "UNLISTED PASTES - https://netbootcamp.org/pastesearch.html#gsc.tab=0 \n",
      "TIKTOK - https://www.tiktok.com/node/share/user/@UserName\n",
      "use X-Rate-Limit-Daily-Remaining header to see remaining searches on emailrep.io\n",
      "If successfully find username use - https://github.com/woj-ciech/SocialPath.git\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''STUFF TO KEEP AT THE BACK OF MIND\n",
    "Below are methods to find a web element based on the locators in Selenium python bindings:\n",
    "find_element_by_id.\n",
    "find_element_by_name.\n",
    "find_element_by_xpath.\n",
    "find_element_by_link_text.\n",
    "find_element_by_partial_link_text.\n",
    "find_element_by_tag_name.\n",
    "find_element_by_class_name.\n",
    "find_element_by_css_selector.\n",
    "LINKEDIN - https://www.linkedin.com/sales/gmail/profile/viewByEmail/\n",
    "UNLISTED PASTES - https://netbootcamp.org/pastesearch.html#gsc.tab=0 \n",
    "TIKTOK - https://www.tiktok.com/node/share/user/@UserName\n",
    "use X-Rate-Limit-Daily-Remaining header to see remaining searches on emailrep.io\n",
    "If successfully find username use - https://github.com/woj-ciech/SocialPath.git\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter target email : contact.shiva@gmail.com\n"
     ]
    }
   ],
   "source": [
    "#NEEDED LIBRARIES\n",
    "import sys\n",
    "from os import path\n",
    "from requests import get,session,packages\n",
    "from bs4 import BeautifulSoup as bs,Comment\n",
    "\n",
    "#!pip3 install webdriver_manager\n",
    "#Just webdriver shit\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "import json \n",
    "import re\n",
    "import csv\n",
    "from time import sleep\n",
    "from urllib.parse import unquote\n",
    "\n",
    "#The next two lines are just to disable the stupid insecure request warning\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "packages.urllib3.disable_warnings(category = InsecureRequestWarning)\n",
    "\n",
    "#options = webdriver.ChromeOptions()\n",
    "#options.add_argument(\"headless\")\n",
    "#options.add_argument('window-size=1200x600');\n",
    "\n",
    "#MAJOR WEBSITES\n",
    "twitter_url = \"https://twitter.com\"\n",
    "insta_url = \"https://www.instagram.com\"\n",
    "fb_url = \"https://www.facebook.com/public\"\n",
    "hibp= \"https://haveibeenpwned.com/unifiedsearch\"\n",
    "email_rep=\"https://emailrep.io\"\n",
    "\n",
    "check = '^[a-z0-9]+[\\._]?[a-z0-9]+@\\w+\\.\\w{2,3}$'\n",
    "ran_once=False\n",
    "target_email=\"\"\n",
    "while not re.search(check, target_email):\n",
    "    target_email=input(\"Please enter target email : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOWNLOAD FUNCTION\n",
    "def download(username,site_name,dp_url): \n",
    "    count = 0 \n",
    "    filename = f\"{username}'s_{site_name}_dp.jpg\" \n",
    "    while True: \n",
    "        if not path.isfile(filename): \n",
    "            with open(filename, 'wb+') as handle: \n",
    "                response = get(dp_url, stream=True)\n",
    "                if not response.ok: \n",
    "                    print(response)\n",
    "                for block in response.iter_content(1024): \n",
    "                    if not block: \n",
    "                        break \n",
    "                    handle.write(block) \n",
    "        else: \n",
    "            count += 1 \n",
    "            filename = f\"{username}'s_{site_name}_dp_{count}.jpg\" \n",
    "            continue \n",
    "        print(f\"{username}'s {site_name} dp downloaded!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Headless\n",
      "\n",
      "{\n",
      "    \"Breaches\": [\n",
      "        {\n",
      "            \"Name\": \"db8151dd\",\n",
      "            \"Title\": \"Covve\",\n",
      "            \"Domain\": \"covve.com\",\n",
      "            \"BreachDate\": \"2020-02-20\",\n",
      "            \"AddedDate\": \"2020-05-15T08:06:11Z\",\n",
      "            \"ModifiedDate\": \"2020-05-19T20:25:18Z\",\n",
      "            \"PwnCount\": 22802117,\n",
      "            \"Description\": \"In February 2020, <a href='https://www.troyhunt.com/the-unattributable-db8151dd-data-breach' target='_blank' rel='noopener'>a massive trove of personal information referred to as &quot;db8151dd&quot;</a> was provided to HIBP after being found left exposed on a publicly facing Elasticsearch server. Later identified as originating from the Covve contacts app, the exposed data included extensive personal information and interactions between Covve users and their contacts. The data was provided to HIBP by <a href='https://dehashed.com/' target='_blank' rel='noopener'>dehashed.com</a>.\",\n",
      "            \"LogoPath\": \"https://haveibeenpwned.com/Content/Images/PwnedLogos/Covve.png\",\n",
      "            \"DataClasses\": [\n",
      "                \"Email addresses\",\n",
      "                \"Job titles\",\n",
      "                \"Names\",\n",
      "                \"Phone numbers\",\n",
      "                \"Physical addresses\",\n",
      "                \"Social media profiles\"\n",
      "            ],\n",
      "            \"IsVerified\": true,\n",
      "            \"IsFabricated\": false,\n",
      "            \"IsSensitive\": false,\n",
      "            \"IsRetired\": false,\n",
      "            \"IsSpamList\": false\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"Dailymotion\",\n",
      "            \"Title\": \"Dailymotion\",\n",
      "            \"Domain\": \"dailymotion.com\",\n",
      "            \"BreachDate\": \"2016-10-20\",\n",
      "            \"AddedDate\": \"2017-08-07T02:51:12Z\",\n",
      "            \"ModifiedDate\": \"2017-08-07T02:51:12Z\",\n",
      "            \"PwnCount\": 85176234,\n",
      "            \"Description\": \"In October 2016, the video sharing platform <a href='http://thehackernews.com/2016/12/dailymotion-video-hacked.html' target='_blank' rel='noopener'>Dailymotion suffered a data breach</a>. The attack led to the exposure of more than 85 million user accounts and included email addresses, usernames and bcrypt hashes of passwords.\",\n",
      "            \"LogoPath\": \"https://haveibeenpwned.com/Content/Images/PwnedLogos/Dailymotion.png\",\n",
      "            \"DataClasses\": [\n",
      "                \"Email addresses\",\n",
      "                \"Passwords\",\n",
      "                \"Usernames\"\n",
      "            ],\n",
      "            \"IsVerified\": true,\n",
      "            \"IsFabricated\": false,\n",
      "            \"IsSensitive\": false,\n",
      "            \"IsRetired\": false,\n",
      "            \"IsSpamList\": false\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"PDL\",\n",
      "            \"Title\": \"Data Enrichment Exposure From PDL Customer\",\n",
      "            \"Domain\": \"\",\n",
      "            \"BreachDate\": \"2019-10-16\",\n",
      "            \"AddedDate\": \"2019-11-22T20:13:04Z\",\n",
      "            \"ModifiedDate\": \"2019-11-22T20:13:04Z\",\n",
      "            \"PwnCount\": 622161052,\n",
      "            \"Description\": \"In October 2019, <a href='https://www.troyhunt.com/data-enrichment-people-data-labs-and-another-622m-email-addresses' target='_blank' rel='noopener'>security researchers Vinny Troia and Bob Diachenko identified an unprotected Elasticsearch server holding 1.2 billion records of personal data</a>. The exposed data included an index indicating it was sourced from data enrichment company People Data Labs (PDL) and contained 622 million unique email addresses. The server was not owned by PDL and it's believed a customer failed to properly secure the database. Exposed information included email addresses, phone numbers, social media profiles and job history data.\",\n",
      "            \"LogoPath\": \"https://haveibeenpwned.com/Content/Images/PwnedLogos/List.png\",\n",
      "            \"DataClasses\": [\n",
      "                \"Email addresses\",\n",
      "                \"Employers\",\n",
      "                \"Geographic locations\",\n",
      "                \"Job titles\",\n",
      "                \"Names\",\n",
      "                \"Phone numbers\",\n",
      "                \"Social media profiles\"\n",
      "            ],\n",
      "            \"IsVerified\": true,\n",
      "            \"IsFabricated\": false,\n",
      "            \"IsSensitive\": false,\n",
      "            \"IsRetired\": false,\n",
      "            \"IsSpamList\": false\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"Dropbox\",\n",
      "            \"Title\": \"Dropbox\",\n",
      "            \"Domain\": \"dropbox.com\",\n",
      "            \"BreachDate\": \"2012-07-01\",\n",
      "            \"AddedDate\": \"2016-08-31T00:19:19Z\",\n",
      "            \"ModifiedDate\": \"2016-08-31T00:19:19Z\",\n",
      "            \"PwnCount\": 68648009,\n",
      "            \"Description\": \"In mid-2012, Dropbox suffered a data breach which exposed the stored credentials of tens of millions of their customers. In August 2016, <a href='https://motherboard.vice.com/read/dropbox-forces-password-resets-after-user-credentials-exposed' target='_blank' rel='noopener'>they forced password resets for customers they believed may be at risk</a>. A large volume of data totalling over 68 million records <a href='https://motherboard.vice.com/read/hackers-stole-over-60-million-dropbox-accounts' target='_blank' rel='noopener'>was subsequently traded online</a> and included email addresses and salted hashes of passwords (half of them SHA1, half of them bcrypt).\",\n",
      "            \"LogoPath\": \"https://haveibeenpwned.com/Content/Images/PwnedLogos/Dropbox.png\",\n",
      "            \"DataClasses\": [\n",
      "                \"Email addresses\",\n",
      "                \"Passwords\"\n",
      "            ],\n",
      "            \"IsVerified\": true,\n",
      "            \"IsFabricated\": false,\n",
      "            \"IsSensitive\": false,\n",
      "            \"IsRetired\": false,\n",
      "            \"IsSpamList\": false\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"LinkedIn\",\n",
      "            \"Title\": \"LinkedIn\",\n",
      "            \"Domain\": \"linkedin.com\",\n",
      "            \"BreachDate\": \"2012-05-05\",\n",
      "            \"AddedDate\": \"2016-05-21T21:35:40Z\",\n",
      "            \"ModifiedDate\": \"2016-05-21T21:35:40Z\",\n",
      "            \"PwnCount\": 164611595,\n",
      "            \"Description\": \"In May 2016, <a href='https://www.troyhunt.com/observations-and-thoughts-on-the-linkedin-data-breach' target='_blank' rel='noopener'>LinkedIn had 164 million email addresses and passwords exposed</a>. Originally hacked in 2012, the data remained out of sight until being offered for sale on a dark market site 4 years later. The passwords in the breach were stored as SHA1 hashes without salt, the vast majority of which were quickly cracked in the days following the release of the data.\",\n",
      "            \"LogoPath\": \"https://haveibeenpwned.com/Content/Images/PwnedLogos/LinkedIn.png\",\n",
      "            \"DataClasses\": [\n",
      "                \"Email addresses\",\n",
      "                \"Passwords\"\n",
      "            ],\n",
      "            \"IsVerified\": true,\n",
      "            \"IsFabricated\": false,\n",
      "            \"IsSensitive\": false,\n",
      "            \"IsRetired\": false,\n",
      "            \"IsSpamList\": false\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"LiveJournal\",\n",
      "            \"Title\": \"LiveJournal\",\n",
      "            \"Domain\": \"livejournal.com\",\n",
      "            \"BreachDate\": \"2017-01-01\",\n",
      "            \"AddedDate\": \"2020-05-26T22:05:10Z\",\n",
      "            \"ModifiedDate\": \"2020-05-26T23:08:58Z\",\n",
      "            \"PwnCount\": 26372781,\n",
      "            \"Description\": \"In mid-2019, <a href='https://news.ycombinator.com/item?id=20426997&fbclid=IwAR22KoBod2B44XzYbPziwh1RoT_M8ll3Uf8Ods7TpF8mPdSGo3PKYQEx9_k' target='_blank' rel='noopener'>news broke of an alleged LiveJournal data breach</a>. This followed <a href='https://twitter.com/rahaeli/status/1265316773508927488' target='_blank' rel='noopener'>multiple reports of credential abuse against Dreamwidth beginning in 2018</a>, a fork of LiveJournal with a significant crossover in user base. The breach allegedly dates back to 2017 and contains 26M unique usernames and email addresses (both of which have been confirmed to exist on LiveJournal) alongside plain text passwords. An archive of the data was subsequently shared on a popular hacking forum in May 2020 and redistributed broadly. The data was provided to HIBP by a source who requested it be attributed to &quot;nano@databases.pw&quot;.\",\n",
      "            \"LogoPath\": \"https://haveibeenpwned.com/Content/Images/PwnedLogos/LiveJournal.png\",\n",
      "            \"DataClasses\": [\n",
      "                \"Email addresses\",\n",
      "                \"Passwords\",\n",
      "                \"Usernames\"\n",
      "            ],\n",
      "            \"IsVerified\": true,\n",
      "            \"IsFabricated\": false,\n",
      "            \"IsSensitive\": false,\n",
      "            \"IsRetired\": false,\n",
      "            \"IsSpamList\": false\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"Yatra\",\n",
      "            \"Title\": \"Yatra\",\n",
      "            \"Domain\": \"yatra.com\",\n",
      "            \"BreachDate\": \"2013-09-01\",\n",
      "            \"AddedDate\": \"2018-07-04T23:15:57Z\",\n",
      "            \"ModifiedDate\": \"2018-07-04T23:15:57Z\",\n",
      "            \"PwnCount\": 5033997,\n",
      "            \"Description\": \"In September 2013, the Indian bookings website known as <a href='https://www.yatra.com/' target='_blank' rel='noopener'>Yatra</a> had 5 million records exposed in a data breach. The data contained email and physical addresses, dates of birth and phone numbers along with both PINs and passwords stored in plain text. The site was previously reported as compromised on the <a href='https://vigilante.pw/' target='_blank' rel='noopener'>Vigilante.pw</a> breached database directory.\",\n",
      "            \"LogoPath\": \"https://haveibeenpwned.com/Content/Images/PwnedLogos/Yatra.png\",\n",
      "            \"DataClasses\": [\n",
      "                \"Dates of birth\",\n",
      "                \"Email addresses\",\n",
      "                \"Names\",\n",
      "                \"Passwords\",\n",
      "                \"Phone numbers\",\n",
      "                \"Physical addresses\",\n",
      "                \"PINs\"\n",
      "            ],\n",
      "            \"IsVerified\": true,\n",
      "            \"IsFabricated\": false,\n",
      "            \"IsSensitive\": false,\n",
      "            \"IsRetired\": false,\n",
      "            \"IsSpamList\": false\n",
      "        }\n",
      "    ],\n",
      "    \"Pastes\": null\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "}\n"
     ]
    }
   ],
   "source": [
    "#HAVE I BEEN PWNED\n",
    "#email=input(\"Enter your email-id : \").lower().replace(\"@\",\"%40\")\n",
    "#target_email=\"mansirao2001@gmail.com\"\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Firefox(options=options)\n",
    "print(\"Initialized Headless\")\n",
    "print()\n",
    "driver.get(f\"{hibp}/{target_email}\")\n",
    "soup = bs(driver.page_source)\n",
    "data = json.loads(soup.find(\"body\").text)\n",
    "print(json.dumps(data,indent = 4).replace(\"\\\\\\\"\",\"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"email\": \"contact.shiva@gmail.com\",\n",
      "  \"reputation\": \"high\",\n",
      "  \"suspicious\": false,\n",
      "  \"references\": 10,\n",
      "  \"details\": {\n",
      "    \"blacklisted\": false,\n",
      "    \"malicious_activity\": false,\n",
      "    \"malicious_activity_recent\": false,\n",
      "    \"credentials_leaked\": true,\n",
      "    \"credentials_leaked_recent\": false,\n",
      "    \"data_breach\": true,\n",
      "    \"first_seen\": \"05/05/2012\",\n",
      "    \"last_seen\": \"02/20/2020\",\n",
      "    \"domain_exists\": true,\n",
      "    \"domain_reputation\": \"n/a\",\n",
      "    \"new_domain\": false,\n",
      "    \"days_since_domain_creation\": 9058,\n",
      "    \"suspicious_tld\": false,\n",
      "    \"spam\": false,\n",
      "    \"free_provider\": true,\n",
      "    \"disposable\": false,\n",
      "    \"deliverable\": true,\n",
      "    \"accept_all\": false,\n",
      "    \"valid_mx\": true,\n",
      "    \"spoofable\": true,\n",
      "    \"spf_strict\": true,\n",
      "    \"dmarc_enforced\": false,\n",
      "    \"profiles\": [\n",
      "      \"twitter\",\n",
      "      \"spotify\",\n",
      "      \"pinterest\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#EMAIL REP\n",
    "#email=\"mansirao2001@gmail.com\"\n",
    "headers={\n",
    "    \"User-Agent\" : \"python/emailrep.io\",\n",
    "    \"Content-Type\" : \"application/json\",\n",
    "    \"Key\" : \"9u880v5bumdu7m37c9zipnv3kwyq1bb3izmuxpwjjvrj3gnv\"\n",
    "}\n",
    "email_rep_data = get(f\"{email_rep}/{target_email}\",headers=headers).content\n",
    "email_rep_data = json.loads(email_rep_data)\n",
    "print(json.dumps(email_rep_data, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.facebook.com/contactshiva\n",
      "https://www.instagram.com/contactshiva\n",
      "https://www.pinterest.com/contactshiva/\n",
      "https://www.twitter.com/contactshiva\n"
     ]
    }
   ],
   "source": [
    "#SHERLOCK\n",
    "from sherlock import sherlock\n",
    "sites_we_need = [\n",
    "                 \"Facebook\",\n",
    "                 \"Instagram\",\n",
    "                 \"Twitter\",\n",
    "                 \"Linkedin\",\n",
    "                 \"Medium\"\n",
    "                ]\n",
    "try:\n",
    "    sites_we_need.extend(list(i.title() for i in email_rep_data[\"details\"][\"profiles\"]))\n",
    "except Exception as e:\n",
    "    pass\n",
    "data = open(\"new_data.json\")\n",
    "sites = json.load(data)\n",
    "username = target_email[:target_email.index('@')].replace(\".\",\"\")\n",
    "results = sherlock(username, sites, print_found_only=True, color=False)\n",
    "exists = []\n",
    "with open(username + \".csv\", \"w\", newline='', encoding=\"utf-8\") as csv_report:\n",
    "    writer = csv.writer(csv_report)\n",
    "    for site in results:\n",
    "        if site in sites_we_need and results[site]['http_status']!=404:\n",
    "            exists.append(site)\n",
    "            towrite=[site,results[site]['url_user']]\n",
    "            print(results[site]['url_user'])\n",
    "            writer.writerow(towrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact.shiva@gmail.com\n",
      "Headless initialized\n",
      "email done\n",
      "logged in\n",
      "jumped to contacts\n",
      "Added contact and got google maps url\n",
      "jumped to maps\n",
      "Google maps url :  https://www.google.com/maps/contrib/107999659639731234903\n",
      "Name :  Shiva Shankar\n"
     ]
    }
   ],
   "source": [
    "#Getting Name from email\n",
    "#Logging into Google\n",
    "#target_email=\"contact.shiva@icloud.com\"\n",
    "#options = Options()\n",
    "#options.headless = True\n",
    "print(target_email)\n",
    "driver = webdriver.Firefox(options=options)\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://stackoverflow.com/users/signup?ssrc=head&returnurl=%2fusers%2fstory%2fcurrent%27')\n",
    "print(\"Headless initialized\")\n",
    "sleep(2)\n",
    "driver.find_element_by_xpath('//*[@id=\"openid-buttons\"]/button[1]').click()\n",
    "driver.find_element_by_xpath('//input[@type=\"email\"]').send_keys('mydbmsproject2001@gmail.com'+Keys.ENTER)\n",
    "print(\"email done\")\n",
    "sleep(3)\n",
    "driver.find_element_by_xpath('//input[@type=\"password\"]').send_keys('g00dpassw0rd'+Keys.ENTER)\n",
    "wait.until(EC.presence_of_element_located((By.ID, \"content\")))\n",
    "print(\"logged in\")\n",
    "sleep(2)\n",
    "#Adding target as contact to google contacts\n",
    "driver.get(\"https://contacts.google.com/\")\n",
    "print(\"jumped to contacts\")\n",
    "sleep(2)\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, '//*[@title=\"Add new contact\"]'))).click()\n",
    "#driver.find_element_by_xpath('//*[@title=\"Add new contact\"]').click()\n",
    "sleep(2)\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, '//*[@aria-label=\"Create a contact\"]'))).click()\n",
    "#wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'whsOnd zHQkBf'))).send_keys(target_email)\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[7]/div[4]/div/div[2]/span/div/div[2]/div[1]/div/div/div[6]/div/div/div[2]/div[1]/div[1]/div/div[1]/input'))).send_keys(target_email)\n",
    "#driver.find_element_by_xpath('/html/body/div[7]/div[4]/div/div[2]/span/div/div[2]/div[1]/div/div/div[6]/div/div/div[2]/div[1]/div[1]/div/div[1]/input').send_keys(target_email)\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, '//*[@jsname=\"x8hlje\"]'))).click()\n",
    "sleep(2)\n",
    "try:\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"ONOzI\")))\n",
    "except:\n",
    "    driver.save_screenshot('test.png')\n",
    "page = driver.page_source\n",
    "target_contact_soup = bs(page,'html.parser')\n",
    "try:\n",
    "    target_id = target_contact_soup.find('div',{\"class\":\"NVFbjd LAORIe\"}).attrs['data-sourceid']\n",
    "    print(\"Added contact and got google maps url\")\n",
    "\n",
    "\n",
    "    # Bounce to maps and get name\n",
    "    maps_url = f\"https://www.google.com/maps/contrib/{target_id}\"\n",
    "    print(\"jumped to maps\")\n",
    "    print(\"Google maps url : \",maps_url)\n",
    "    driver.get(f\"https://www.google.com/maps/contrib/{target_id}\")\n",
    "    wait.until(EC.presence_of_element_located((By.TAG_NAME, \"h1\")))\n",
    "    name_page=driver.page_source\n",
    "    name_soup=bs(name_page,'html.parser')\n",
    "    name=name_soup.find(\"h1\",{\"role\":\"button\",\"class\":\"section-profile-header-name section-profile-header-clickable-item\"}).text\n",
    "    print(\"Name : \",name)\n",
    "except Exception as e:\n",
    "    driver.save_screenshot('error.png')\n",
    "    print(\"Sorry this email is not linked to a google account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"logging_page_id\": \"profilePage_257130609\",\n",
      "    \"show_suggested_profiles\": false,\n",
      "    \"show_follow_dialog\": false,\n",
      "    \"graphql\": {\n",
      "        \"user\": {\n",
      "            \"biography\": \"\",\n",
      "            \"blocked_by_viewer\": false,\n",
      "            \"restricted_by_viewer\": null,\n",
      "            \"country_block\": false,\n",
      "            \"external_url\": null,\n",
      "            \"external_url_linkshimmed\": null,\n",
      "            \"edge_followed_by\": {\n",
      "                \"count\": 246\n",
      "            },\n",
      "            \"followed_by_viewer\": false,\n",
      "            \"edge_follow\": {\n",
      "                \"count\": 214\n",
      "            },\n",
      "            \"follows_viewer\": false,\n",
      "            \"full_name\": \"Shiva Shankar\",\n",
      "            \"has_ar_effects\": false,\n",
      "            \"has_channel\": false,\n",
      "            \"has_blocked_viewer\": false,\n",
      "            \"highlight_reel_count\": 0,\n",
      "            \"has_requested_viewer\": false,\n",
      "            \"id\": \"257130609\",\n",
      "            \"is_business_account\": false,\n",
      "            \"is_joined_recently\": false,\n",
      "            \"business_category_name\": null,\n",
      "            \"category_id\": null,\n",
      "            \"overall_category_name\": null,\n",
      "            \"category_enum\": null,\n",
      "            \"is_private\": true,\n",
      "            \"is_verified\": false,\n",
      "            \"edge_mutual_followed_by\": {\n",
      "                \"count\": 0,\n",
      "                \"edges\": []\n",
      "            },\n",
      "            \"profile_pic_url\": \"https://instagram.fbom3-1.fna.fbcdn.net/v/t51.2885-19/s150x150/28754482_866848763494062_5456544272104816640_n.jpg?_nc_ht=instagram.fbom3-1.fna.fbcdn.net&_nc_ohc=gPasPTzL2YAAX9ozfVc&oh=864abd0b021a8396582ef4f2bde55cb9&oe=5EFC8601\",\n",
      "            \"profile_pic_url_hd\": \"https://instagram.fbom3-1.fna.fbcdn.net/v/t51.2885-19/s320x320/28754482_866848763494062_5456544272104816640_n.jpg?_nc_ht=instagram.fbom3-1.fna.fbcdn.net&_nc_ohc=gPasPTzL2YAAX9ozfVc&oh=5efa9698a684ff413a1145f7b85132c7&oe=5EFE22F1\",\n",
      "            \"requested_by_viewer\": false,\n",
      "            \"username\": \"contactshiva\",\n",
      "            \"connected_fb_page\": null,\n",
      "            \"edge_felix_video_timeline\": {\n",
      "                \"count\": 0,\n",
      "                \"page_info\": {\n",
      "                    \"has_next_page\": false,\n",
      "                    \"end_cursor\": null\n",
      "                },\n",
      "                \"edges\": []\n",
      "            },\n",
      "            \"edge_owner_to_timeline_media\": {\n",
      "                \"count\": 4,\n",
      "                \"page_info\": {\n",
      "                    \"has_next_page\": false,\n",
      "                    \"end_cursor\": null\n",
      "                },\n",
      "                \"edges\": []\n",
      "            },\n",
      "            \"edge_saved_media\": {\n",
      "                \"count\": 0,\n",
      "                \"page_info\": {\n",
      "                    \"has_next_page\": false,\n",
      "                    \"end_cursor\": null\n",
      "                },\n",
      "                \"edges\": []\n",
      "            },\n",
      "            \"edge_media_collections\": {\n",
      "                \"count\": 0,\n",
      "                \"page_info\": {\n",
      "                    \"has_next_page\": false,\n",
      "                    \"end_cursor\": null\n",
      "                },\n",
      "                \"edges\": []\n",
      "            },\n",
      "            \"edge_related_profiles\": {\n",
      "                \"edges\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"toast_content_on_load\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#INSTA INFO\n",
    "if \"Instagram\" in exists:\n",
    "    #options = Options()\n",
    "    #options.headless = True\n",
    "    #driver = webdriver.Firefox(options=options)\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    driver.get(results[\"Instagram\"][\"url_user\"])\n",
    "    user_page = driver.page_source\n",
    "    insta_soup = bs(user_page,'html.parser')\n",
    "    if not insta_soup.find(text=\"Sorry, this page isn't available.\"):\n",
    "        scripts = insta_soup.find('script', type=\"text/javascript\", text=re.compile('window._sharedData'))\n",
    "        stringified_json = scripts.text.replace('window._sharedData = ', '')[:-1]\n",
    "        insta_data = json.loads(stringified_json)['entry_data']['ProfilePage'][0]\n",
    "        insta_username = insta_data['graphql']['user']['username']\n",
    "        if not path.isfile(f\"{insta_username}'s_insta_data.json\"):\n",
    "            data_file = f\"{insta_username}'s_insta_data.json\" \n",
    "        else:\n",
    "            data_file = f\"{insta_username}'s_insta_data_1.json\"\n",
    "        #json.dump(insta_data, open(data_file,\"w+\"), indent=4)\n",
    "        print(json.dumps(insta_data, indent=4))\n",
    "    else:\n",
    "        print(\"Sorry this insta account does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOWNLOAD INSTA DP\n",
    "dp_url = insta_data['graphql']['user']['profile_pic_url_hd']\n",
    "filename = f\"{insta_username}'s_insta_dp.jpg\"\n",
    "download(insta_username,\"insta\",dp_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TWITTER INFO\n",
    "if \"Twitter\" in exists:\n",
    "    print(results[\"Twitter\"][\"url_user\"])\n",
    "    #driver.get(results[\"Twitter\"][\"url_user\"])\n",
    "    page = get(results[\"Twitter\"][\"url_user\"]).content\n",
    "    html = bs(page,'html.parser')\n",
    "    # TODO: Check what kind of exception raising if no location\n",
    "    location = html.find(\"span\",{\"class\":\"ProfileHeaderCard-locationText u-dir\"}).text\n",
    "    birthday = html.find(\"span\",{\"class\":\"ProfileHeaderCard-birthdateText u-dir\"}).text.strip()\n",
    "    if birthday:\n",
    "        birthday = birthday.replace('Born ', '')\n",
    "    else:\n",
    "        birthday = None\n",
    "    profile_photo = html.find(\"img\",{\"class\":\"ProfileAvatar-image\"}).attrs['src']\n",
    "    page_title = html.find('title').text\n",
    "    name = page_title[:page_title.find('(')].strip()\n",
    "    biography = html.find(\"p\",{\"class\":\"ProfileHeaderCard-bio u-dir\"}).text\n",
    "    #website = html.find(\"a\",{\"class\":\"u-textUserColor\",\"rel\":\"me nofollow noopener\"}).text.strip()\n",
    "    print(json.dumps(dict(\n",
    "    twitter_name = name,\n",
    "    twitter_username = username,\n",
    "    twitter_birthday = birthday,\n",
    "    biography = biography,\n",
    "    profile_photo = profile_photo ), indent=4))\n",
    "    #download(twit_username,\"twitter\",profile_photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FACEBOOK INFO\n",
    "fb_username = insta_data['graphql']['user']['full_name'].lower()\n",
    "page = get(f\"{fb_url}/{fb_username}\",verify = False, headers={'Accept-Language':\"en-us\"})\n",
    "soup = bs(page.content,'html.parser')\n",
    "comment_soup = bs(soup.find(text = lambda text:isinstance(text,Comment)), 'html.parser')\n",
    "print(comment_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_dp = comment_soup.findAll('img',{\"alt\":f\"{fb_username.camelcase()}\"})\n",
    "for dp in fb_dp:\n",
    "    dp_url = dp.attrs[\"src\"]\n",
    "    download(fb_username,\"fb\",dp_url)\n",
    "json.dump(insta_data, open(data_file,\"w+\"), indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
